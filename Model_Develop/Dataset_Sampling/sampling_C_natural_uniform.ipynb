{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "import tqdm\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_kr = {\n",
    "    'c_1' :0, #'종이',\n",
    "    'c_2_01': 1, #'종이팩',\n",
    "    'c_2_02': 2, #'종이컵',\n",
    "    'c_3': 3, #'캔류',\n",
    "    'c_4_01_02': 4, #'재사용 유리(소주병 + 맥주병)',\n",
    "    'c_4_02_01_02': 5, #'갈색 유리',\n",
    "    'c_4_02_02_02': 6, #'녹색 유리',\n",
    "    'c_4_02_03_02': 7, #'백색 유리',\n",
    "    'c_4_03': 8, #'기타 유리',\n",
    "    'c_5_02': 9, #'페트',\n",
    "    'c_6': 10, #'플라스틱',\n",
    "    'c_7': 11, #'비닐',\n",
    "    ## 이 위에는 재활용\n",
    "    ## 밑에는 일반쓰레기\n",
    "    'c_1_01': 12, #'종이 + 이물질',\n",
    "    'c_2_02_01': 13, #'종이컵 + 이물질',\n",
    "    'c_3_01': 14, #'캔 + 이물질',\n",
    "    'c_4_03_01': 15, #'기타 유리 + 이물질',\n",
    "    'c_5_01_01': 16, #'페트 + 이물질 + 다중포장재',\n",
    "    'c_5_02_01' : 17, #'페트+이물질',\n",
    "    'c_6_01': 18, #'플라스틱 + 이물질',\n",
    "    'c_7_01': 19, #'비닐 + 이물질',\n",
    "\n",
    "    # 다중포장재\n",
    "    'c_4_01_01': 20, #'재사용 유리(소주병+맥주병) + 다중 포장재',\n",
    "    'c_4_02_01_01': 21, #'갈색 유리 + 다중포장재',\n",
    "    'c_4_02_02_01': 22, #'녹색 유리 + 다중포장재',\n",
    "    'c_4_02_03_01': 23, #'백색 유리 + 다중포장재',\n",
    "    'c_5_01': 24, #'페트 + 다중포장재',\n",
    "    'c_8_01': 25, #'흰색 스티로폼',\n",
    "    'c_8_02': 26, #'컬러 스티로폼',\n",
    "    'c_8_01_01': 27, #'스티로폼 + 이물질',\n",
    "    'c_9': 28, #'건전지'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 무결성 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 형식 jpg로 통일\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 151440/151440 [00:00<00:00, 4207194.51it/s]\n",
      "151440it [00:00, 912111.60it/s]\n",
      "151440it [00:00, 901262.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제된 이미지 파일 개수 : 0\n",
      "삭제된 json 파일 개수 : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151440it [00:00, 912162.68it/s]\n",
      "151440it [00:00, 909455.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 이미지 개수 : 151440 / json 개수 : 151440\n",
      "공통된 파일 개수 : 151440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "images_path = './mydata/images_folder'\n",
    "json_path = './mydata/jsons_folder'\n",
    "\n",
    "images_list = os.listdir(images_path)\n",
    "json_list = os.listdir(json_path)\n",
    "\n",
    "print('이미지 형식 jpg로 통일')\n",
    "for file_name in tqdm.tqdm(images_list):\n",
    "    if file_name.endswith('.JPG'):\n",
    "        new_file_name = file_name.replace('.JPG', '.jpg')\n",
    "        old_file_path = os.path.join(images_path, file_name)\n",
    "        new_file_path = os.path.join(images_path, new_file_name)\n",
    "        os.rename(old_file_path, new_file_path)\n",
    "\n",
    "for file_list in [images_list,json_list]:\n",
    "    for idx , file_name in tqdm.tqdm(enumerate(file_list)):\n",
    "        file_list[idx] = os.path.splitext(file_name)[0]\n",
    "\n",
    "cnt = 0\n",
    "for file_name in images_list:\n",
    "    if file_name not in json_list: \n",
    "        os.remove(os.path.join(images_path,file_name+'.jpg'))\n",
    "        cnt += 1\n",
    "print(f'삭제된 이미지 파일 개수 : {cnt}')\n",
    "\n",
    "cnt = 0\n",
    "for file_name in json_list:\n",
    "    if file_name not in images_list: \n",
    "        os.remove(os.path.join(json_path,file_name+'.json'))\n",
    "        cnt += 1\n",
    "print(f'삭제된 json 파일 개수 : {cnt}')\n",
    "\n",
    "images_list = os.listdir(images_path)\n",
    "json_list = os.listdir(json_path)\n",
    "for file_list in [images_list,json_list]:\n",
    "    for idx , file_name in tqdm.tqdm(enumerate(file_list)):\n",
    "        file_list[idx] = os.path.splitext(file_name)[0]\n",
    "print(f'최종 이미지 개수 : {len(images_list)} / json 개수 : {len(json_list)}')\n",
    "\n",
    "inter_list = set(images_list+json_list)\n",
    "print(f'공통된 파일 개수 : {len(inter_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uniform 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144913/144913 [00:36<00:00, 3965.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[567, 56, 87, 477, 1171, 3, 1199, 14, 21, 199, 286, 728, 70, 87, 216, 50, 167, 146, 327, 1199, 176, 159, 1199, 141, 261, 101, 0, 1199, 65]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139136/139136 [00:47<00:00, 2942.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200, 1200, 1200, 1200, 1171, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118986/118986 [00:26<00:00, 4539.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200, 1200, 1200, 1201, 1182, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1205, 1200, 1200, 1201, 1201, 1200, 1200, 1200, 1205, 1200]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118975/118975 [00:26<00:00, 4497.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200, 1200, 1200, 1201, 1182, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1205, 1200, 1200, 1201, 1201, 1200, 1200, 1200, 1205, 1200]\n",
      "[1200, 1200, 1200, 1201, 1182, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1205, 1200, 1200, 1201, 1201, 1200, 1200, 1200, 1205, 1200]\n",
      "25938\n",
      "25938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 폴더 명 확인인\n",
    "\n",
    "max_val = 1230\n",
    "min_val = 1200\n",
    "AB_path = './mydata/jsons_folder' # json파일만 들어있음\n",
    "to_path = './mydata/uniform_data/train/labels'\n",
    "seed = 1111\n",
    "\n",
    "special = [4 , 6 , 19, 22,27]\n",
    "\n",
    "json_list=[]\n",
    "AB_label_count=[0 for _ in range(29)]\n",
    "break_x = False\n",
    "\n",
    "AB_label_list = os.listdir(AB_path)\n",
    "random.Random(seed).shuffle(AB_label_list) # random shuffling\n",
    "for file_name in tqdm.tqdm(AB_label_list):\n",
    "    temp_list = [0 for _ in range(29)]\n",
    "    with open(os.path.join(AB_path,file_name), 'r',encoding=\"UTF-8\") as file:\n",
    "        data = json.load(file)\n",
    "    for dictionary in data[\"objects\"]:\n",
    "        temp_list[label_kr[dictionary['class_name']]] += 1\n",
    "    if sum(temp_list[idx] for idx in special) and all((AB_label_count[idx] + temp_list[idx] < min_val) for idx in range(29)):\n",
    "        for i in range(29):\n",
    "            AB_label_count[i] += temp_list[i]\n",
    "        json_list.append(file_name)\n",
    "        shutil.move(os.path.join(AB_path,file_name) , os.path.join(to_path,file_name))\n",
    "    \n",
    "print(AB_label_count)\n",
    "\n",
    "for patience in range(3):\n",
    "    AB_label_list = os.listdir(AB_path)\n",
    "    random.Random(seed).shuffle(AB_label_list) # random shuffling\n",
    "\n",
    "    for file_name in tqdm.tqdm(AB_label_list):\n",
    "        if all(AB_label_count[i]<min_val for i in range(29)):\n",
    "            with open(os.path.join(AB_path,file_name), 'r',encoding=\"UTF-8\") as file:\n",
    "                data = json.load(file)\n",
    "            for dictionary in data[\"objects\"]:\n",
    "                AB_label_count[label_kr[dictionary['class_name']]] += 1\n",
    "            json_list.append(file_name)\n",
    "            shutil.move(os.path.join(AB_path,file_name) , os.path.join(to_path,file_name))\n",
    "            pass\n",
    "\n",
    "        elif any(AB_label_count[i]<min_val for i in range(29)):\n",
    "            need_list = [1 if x < min_val else 0 for x in AB_label_count]\n",
    "            temp_list = [0 for _ in range(29)]\n",
    "            with open(os.path.join(AB_path,file_name), 'r',encoding=\"UTF-8\") as file:\n",
    "                data = json.load(file)\n",
    "            for dictionary in data[\"objects\"]:\n",
    "                temp_list[label_kr[dictionary['class_name']]] += 1\n",
    "\n",
    "            go_x = True\n",
    "            cnt = 0\n",
    "            for i in range(29):\n",
    "                if need_list[i]:\n",
    "                    if temp_list[i] > 0:\n",
    "                        cnt += 1\n",
    "                else:\n",
    "                    if temp_list[i] > 2*patience or (AB_label_count[i] > max_val + 2*(patience**2)) :\n",
    "                        go_x = False\n",
    "                        break\n",
    "\n",
    "                        \n",
    "            if go_x and cnt:\n",
    "                for i in range(29):\n",
    "                    AB_label_count[i] +=  temp_list[i]\n",
    "                json_list.append(file_name)\n",
    "                shutil.move(os.path.join(AB_path,file_name) , os.path.join(to_path,file_name))\n",
    "            \n",
    "        if all(AB_label_count[i]>=min_val for i in range(29)):\n",
    "            break_x = True\n",
    "            break\n",
    "     \n",
    "    if break_x:\n",
    "        break     \n",
    "    print(AB_label_count) # samplinge된 클래스별 개수\n",
    "print(AB_label_count) \n",
    "print(len(json_list)) # sampling된 이미지 개수\n",
    "moved_lsit = os.listdir(to_path)\n",
    "print(len(moved_lsit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6527\n"
     ]
    }
   ],
   "source": [
    "# 위에 코드 재실행할 때 사용\n",
    "to_path = './mydata/uniform_data/val/labels'\n",
    "json_list = os.listdir(to_path)\n",
    "cnt = 0\n",
    "for file_name in json_list:\n",
    "    shutil.copy(os.path.join(to_path,file_name) , os.path.join(AB_path,file_name))\n",
    "    #shutil.move(os.path.join(to_path,file_name) , os.path.join(AB_path,file_name))\n",
    "    cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform 분포/ c폴더 4번 인덱스는 최대 값이 1182임\n",
    "[1200, 1200, 1200, 1200, 1182, 1200, 1200, 1200, 1200, 1200, 1200, 1197, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1204, 1200, 1200, 1201, 1201, 1200, 1200, 1200, 1205, 1200]\n",
    "25937\n",
    "\n",
    "[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 301, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300]\n",
    "6527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural 분포/ c폴더 합하면 180,794개\n",
    "[5125, 830, 894, 3604, 249, 531, 268, 543, 330, 977, 4349, 6806, 602, 675, 1136, 1086, 1130, 779, 3490, 375, 1167, 804, 334, 823, 2374, 642, 966, 264, 1078]\n",
    "25000개\n",
    "\n",
    "[1243, 180, 182, 810, 66, 110, 80, 114, 73, 245, 1014, 1679, 170, 160, 259, 261, 253, 173, 819, 100, 288, 199, 80, 183, 622, 144, 265, 73, 253]\n",
    "6000개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자연 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 데이터 : 151440개\n",
      "train data : 25000개\n",
      "valid data : 6000개\n"
     ]
    }
   ],
   "source": [
    "from_path = './mydata/jsons_folder'\n",
    "json_list = os.listdir(from_path)\n",
    "print(f'총 데이터 : {len(json_list)}개')\n",
    "\n",
    "random.seed(1234)  # 랜덤 시드 설정\n",
    "train_list = random.sample(json_list, 25000)\n",
    "to_path = './mydata/natural_data/train/labels'\n",
    "cnt = 0\n",
    "for file_name in train_list:\n",
    "    shutil.move(os.path.join(from_path,file_name) , os.path.join(to_path,file_name))\n",
    "    cnt += 1\n",
    "print(f'train data : {cnt}개')\n",
    "\n",
    "\n",
    "json_list = os.listdir(from_path)\n",
    "\n",
    "random.seed(1234)  # 랜덤 시드 설정\n",
    "train_list = random.sample(json_list, 6000)\n",
    "to_path = './mydata/natural_data/val/labels'\n",
    "cnt = 0\n",
    "for file_name in train_list:\n",
    "    shutil.move(os.path.join(from_path,file_name) , os.path.join(to_path,file_name))\n",
    "    cnt += 1\n",
    "print(f'valid data : {cnt}개')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이미지 Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json 데이터 개수 : 63465\n",
      "중복 없는 데이터 개수 : 56852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 151440/151440 [04:45<00:00, 530.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "필요없는 이미지 제거 완료\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56852/56852 [00:15<00:00, 3667.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json 데이터 총 개수 : 56852\n",
      "json 데이터와 매칭되는 이미지 개수 : 56852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 필요없는 이미지 제거\n",
    "label_path_list = ['./mydata/uniform_data/train/labels',\n",
    "              './mydata/uniform_data/val/labels',\n",
    "              './mydata/natural_data/train/labels',\n",
    "              './mydata/natural_data/val/labels']\n",
    "\n",
    "from_image_path = './mydata/images_folder'\n",
    "\n",
    "label_list = []\n",
    "for label_path in label_path_list:\n",
    "    t_list = os.listdir(label_path)\n",
    "    label_list += t_list\n",
    "print(f'json 데이터 개수 : {len(label_list)}')                  # 62687개가 되야함\n",
    "print(f'중복 없는 데이터 개수 : {len(set(label_list))}')\n",
    "\n",
    "for i,label_name in enumerate(label_list):\n",
    "    label_list[i] = os.path.splitext(label_name)[0]\n",
    "\n",
    "image_list = os.listdir(from_image_path)\n",
    "for image_name in tqdm.tqdm(image_list):\n",
    "    if os.path.splitext(image_name)[0] in label_list:\n",
    "        pass\n",
    "    else:\n",
    "        os.remove(os.path.join(from_image_path,image_name))\n",
    "print('필요없는 이미지 제거 완료')\n",
    "print()\n",
    "\n",
    "# 모든 json파일과 이미지 데이터가 있는지 확인\n",
    "cnt = 0\n",
    "image_list = os.listdir(from_image_path)\n",
    "\n",
    "no_image_label_list = []\n",
    "image_list = os.listdir(from_image_path)\n",
    "for label_name in tqdm.tqdm(set(label_list)):\n",
    "    if label_name + '.jpg' in image_list:\n",
    "        cnt += 1\n",
    "    else:\n",
    "        no_image_label_list.append(label_name)\n",
    "print(f'json 데이터 총 개수 : {len(set(label_list))}')\n",
    "print(f'json 데이터와 매칭되는 이미지 개수 : {cnt}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in sorted(no_image_label_list):\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6000/6000 [14:35<00:00,  6.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from_image_path = './mydata/images_folder'\n",
    "to_image_path = './mydata/natural_data/val/images'\n",
    "label_path = './mydata/natural_data/val/labels'\n",
    "size = (640,640)\n",
    "\n",
    "json_list = os.listdir(label_path)\n",
    "json_list = [file for file in json_list if file.endswith('.json')]\n",
    "for file_name in tqdm.tqdm(json_list):\n",
    "\n",
    "    try:\n",
    "        image = Image.open(os.path.join(from_image_path,os.path.splitext(file_name)[0]+'.jpg'))\n",
    "        h , w = image.size  # 세로,가로\n",
    "        resized_image = image.resize(size)\n",
    "        resized_image.save(os.path.join(to_image_path,os.path.splitext(file_name)[0]+'.jpg'))\n",
    "\n",
    "        with open(os.path.join(label_path,file_name), 'r',encoding=\"UTF-8\") as file:\n",
    "            data = json.load(file)\n",
    "        extracted_objects = []      \n",
    "        for dictionary in data[\"objects\"]:                 \n",
    "            class_name = label_kr[dictionary[\"class_name\"]]\n",
    "            coord_x = dictionary[\"annotation\"][\"coord\"][\"x\"]\n",
    "            coord_y = dictionary[\"annotation\"][\"coord\"][\"y\"]\n",
    "            coord_width = dictionary[\"annotation\"][\"coord\"][\"width\"]\n",
    "            coord_height = dictionary[\"annotation\"][\"coord\"][\"height\"]\n",
    "            extracted_objects.append((class_name, (coord_x+coord_width/2)/w,\n",
    "                                    (coord_y+coord_height/2)/h,coord_width/w,coord_height/h))\n",
    "                            \n",
    "            # 추출한 값을 텍스트 파일로 저장\n",
    "            text_file_name = os.path.splitext(file_name)[0] + '.txt'\n",
    "            text_file_path = os.path.join(label_path, text_file_name)\n",
    "            with open(text_file_path, 'w') as file:\n",
    "                for obj in extracted_objects:\n",
    "                    file.write(' '.join(map(str, obj)) + '\\n')\n",
    "        # json파일 제거\n",
    "        os.remove(os.path.join(label_path,file_name))\n",
    "    except:\n",
    "        print(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform_data 분포 - train : 이미지 개수 : 25935 / txt 개수 : 25935 / 이미지,txt쌍 개수 : 25935\n",
      "[1200, 1200, 1200, 1200, 1182, 1200, 1200, 1200, 1200, 1200, 1200, 1197, 1200, 1200, 1200, 1200, 1200, 1200, 1200, 1204, 1199, 1200, 1201, 1201, 1200, 1200, 1200, 1204, 1200]\n",
      "\n",
      "uniform_data 분포 - val : 이미지 개수 : 6527 / txt 개수 : 6527 / 이미지,txt쌍 개수 : 6527\n",
      "[300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 301, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 299, 300, 300, 300, 300, 300]\n",
      "\n",
      "natural_data 분포 - train : 이미지 개수 : 25000 / txt 개수 : 25000 / 이미지,txt쌍 개수 : 25000\n",
      "[5124, 830, 894, 3604, 249, 531, 268, 543, 330, 977, 4350, 6807, 602, 675, 1136, 1086, 1130, 779, 3490, 375, 1167, 805, 334, 824, 2374, 642, 966, 264, 1078]\n",
      "\n",
      "natural_data 분포 - val : 이미지 개수 : 6000 / txt 개수 : 6000 / 이미지,txt쌍 개수 : 6000\n",
      "[1243, 180, 182, 810, 66, 110, 80, 114, 73, 245, 1014, 1679, 170, 160, 259, 261, 253, 173, 819, 100, 288, 199, 80, 183, 622, 144, 265, 73, 253]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distribution = ['uniform_data','natural_data']\n",
    "tr_vl = ['train','val']\n",
    "\n",
    "for dis in distribution:\n",
    "    for t_v in tr_vl:\n",
    "        from_path = os.path.join('./mydata',dis,t_v)\n",
    "        image_path = os.path.join(from_path,'images')\n",
    "        label_path = os.path.join(from_path,'labels')\n",
    "\n",
    "        image_list = os.listdir(image_path)\n",
    "        label_list = os.listdir(label_path)\n",
    "\n",
    "        json_list = [file for file in label_list if file.endswith('.json')]\n",
    "        if json_list:\n",
    "            print(f'json파일이 존재합니다. : {len(json_list)}')\n",
    "\n",
    "        label_count=[0 for _ in range(29)]\n",
    "\n",
    "        for file_name in label_list:\n",
    "            with open(os.path.join(label_path,file_name), 'r',encoding=\"UTF-8\") as file:\n",
    "                for line in file:\n",
    "                    try:\n",
    "                        label_count[int(line.split()[0])] += 1\n",
    "                    except:\n",
    "                        print(file_name)\n",
    "                        break\n",
    "                    \n",
    "        image_list = [os.path.splitext(v)[0] for v in image_list]\n",
    "        label_list = [os.path.splitext(v)[0] for v in label_list]\n",
    "        image_label_list = set(image_list+label_list)\n",
    "    \n",
    "        print(f'{dis} 분포 - {t_v} : 이미지 개수 : {len(image_list)} / txt 개수 : {len(label_list)} / 이미지,txt쌍 개수 : {len(image_label_list)}')\n",
    "        print(label_count)\n",
    "        print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
